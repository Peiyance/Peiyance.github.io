<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Peiyan Zhang</title>
  
  <meta name="author" content="Peiyan Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="dynGlrBhgI0qHuKVUSWC1DukUTFjbDBK1k4NIGP3Nq0" />
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Peiyan Zhang</name> 
              </p>
              <p>I'm a fifth-year Ph.D. student at the Hong Kong University of Science and Technology (HKUST), supervised by <a href="https://www.cse.ust.hk/~yqsong/">Prof. Yangqiu Song</a> and <a href="https://www.cse.ust.hk/~hunkim/">Prof. Sunghun Kim</a>.
              </p>  
              <p>
                In 2020, I received my Bachelor's Degree in Computer Science and Technology, <a href="https://english.bit.edu.cn/"> Beijing Institute of Technology</a> with the Graduate Excellence Award of Beijing (2020) and National Scholarships (2017-2019).
              </p>
              <p>
                From March 2022 to April 2023, I worked as a research intern at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research Asia</a>, supervised by <a href="https://www.microsoft.com/en-us/research/people/cli/">Chaozhuo Li</a>, and <a href="https://www.microsoft.com/en-us/research/people/xingx/">Xing Xie</a>. My work on recommender systems won the Best Paper Award - Honorable Mention in WSDM 2023. I have won the Award of Excellence of Stars of Tomorrow Internship Program in Microsoft Research Asia (Top 10%).
              </p>
		Since August 2022, I have collaborated with Prof.<a href="https://haohanwang.github.io/"> Haohan Wang</a>'s group at University of Illinois Urbana-Champaign (UIUC), working on trustworthy machine learning systems.
              </p>
		From July 2023 to December 2023, I worked as a research intern at <a href="https://www.baai.ac.cn/english.html"> Beijing Academy of Artificial Intelligence (BAAI)</a>, supervised by Zheng Liu and focusing on large language models (LLM) & retrieval-oriented pre-training algorithms & end-to-end optimized information retrieval systems.
              </p>
		<p>
		  Currently, I am involved in pioneering efforts on <a href="https://guardai.io/"> Guard AI</a>, an Automated AI Vulnerability and Defense Platform that secures AI systems for businesses. We specialize in monitoring, analyzing, and protecting LLMs without accessing internal data. 
		</p>
              <p style="text-align:center">
                <a href="mailto:pzhangao@connect.ust.hk">Email</a> &nbsp/&nbsp
                <a href="data/cv_web.pdf">CV</a> &nbsp/&nbsp
<!-- 		<a href="data/CV_Peiyan_CN.pdf">CV (Chinese)</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=A1_FpIcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- &nbsp/&nbsp -->
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/Peiyance">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images\pyme.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images\pyme_circle.PNG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td>
                  <!-- <heading> -->
                    <!-- <font color="black">News</font> -->
                  <!-- </heading> -->
                  <p>
                  </p><ul>
		<li>News (May. 2025): <strong>üöÄ Excited to release our recent project on LLM reasoning: <font color="red">"Reasoning Can Hurt the Inductive Abilities of Large Language Models"</font>! üöÄ</strong></li>
		<li>News (May. 2025): <strong>üöÄ Excited to release our recent project on LLM hallucinations and jailbreaks: <font color="red">"From Hallucinations to Jailbreaks: Rethinking the Vulnerability of Large Foundation Models"</font>! üöÄ</strong></li>
		<li>News (May. 2025): <strong>üöÄ Excited to release our recent project on LLM jailbreaks: <font color="red">"GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of LLMs"</font>! üöÄ</strong></li>
		<li>News (May. 2025): <strong>Our Paper <font color="red">"REVOLVE: Optimizing AI Systems by Tracking Response Evolution in Textual Optimization"</font> is accepted by ICML 2025.</font>! üöÄ</strong></li>
		<li>News (Apr. 2025): <strong>üöÄ Excited to release our recent survey on AI Agent: <font color="red">"Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems"</font>! üöÄ</strong></li>
		<li>News (Feb. 2025): <strong>Our Paper <font color="red">"Improving Sequential Recommendations via Bidirectional Temporal Data Augmentation with Pre-training"</font> is accepted by TKDE.</strong></li>
		<li>News (Dec. 2024): <strong>üöÄ Excited to release our recent project on LLM Textual Optimization: <font color="red">"REVOLVE: Optimizing AI Systems by Tracking Response Evolution in Textual Optimization"</font>! üöÄ</strong></li>
		<li>News (Aug. 2024): <strong>üöÄ Excited to release our recent survey on Graph Prompt Learning: <font color="red">"Towards Graph Prompt Learning: A Survey and Beyond"</font>! üöÄ</strong></li>
		<li>News (Jul. 2024): <strong>üöÄ Excited to release our recent survey on LLM & VLM Jailbreaking: <font color="red">"JailbreakZoo: Survey, Landscapes, and Horizons in Jailbreaking Large Language and Vision-Language Models"</font>! üöÄ</strong></li>
		    <li>News (Mar. 2024): <strong>Our Paper <font color="red">"GPT4Rec: Graph Prompt Tuning for Streaming Recommendation"</font> is accepted by SIGIR 2024.</strong></li>
		    <li>News (Mar. 2024): <strong>Our Paper <font color="red">"TransGNN: Harnessing the Collaborative Power of Transformer and Graph Neural Network for Recommender Systems"</font> is accepted by SIGIR 2024.</strong></li>
		    <li>News (Jan. 2024): <strong>Our Paper <font color="red">"Inductive Graph Alignment Prompt: Bridging the Gap between Graph Pre-training and Inductive Fine-tuning From Spectral Perspective"</font> is accepted by WWW 2024 (Oral Presentation).</strong></li>
		    <li>News (Jan. 2024): <strong>Our Paper <font color="red">"High-Frequency-aware Hierarchical Contrastive Selective Coding for Representation Learning on Text Attributed Graphs"</font> is accepted by WWW 2024 (Poster Presentation).</strong></li>
		    <li>News (Jan. 2024): <strong>Our Paper <font color="red">"Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models"</font> is accepted by ICLR 2024 (Poster Presentation).</strong></li>
		    <li>News (Jul. 2023): <strong>Our Paper <font color="red">"A Comprehensive Study on Text-attributed Graphs: Benchmarking and Rethinking"</font> is accepted by NeurIPS 2023 (Poster Presentation).</strong></li>
                    <li>News (Jul. 2023): <strong>Our Paper <font color="red">"AdaMCT: Adaptive Mixture of CNN-Transformer for Sequential Recommendation"</font> is accepted by CIKM 2023 (Oral Presentation).</strong></li>
		    <li>News (Jul. 2023): <strong> We presented our work on <font color="red">Practical Content-aware Session-based Recommendation: Deep Retrieve then Shallow Rank</font> at KDDCup 2023 (Oral Presentation).</strong></li>
                    <li>News (Jul. 2023): <strong> We are recognized as <font color="red">Winners of Amazon KDD Cup 2023 Challenge</font>. <a href="https://discourse.aicrowd.com/t/announcing-the-winners-of-amazon-kdd-cup-2023-get-to-know-them/9001"> Rank: 3rd Place in the world!</a></strong></li> 
                    <li>News (Apr. 2023): <strong> I got <font color="red">Award of Excellence of Stars of Tomorrow</font> in Microsoft Research Asia (Top 10%).</strong></li>
<!-- 			    I have won the <b>Award of Excellence of Stars of Tomorrow Internship Program in Microsoft Research Asia (Top 10%)</b>!</li>  -->
                    <li>News (Apr. 2023): <strong> We presented our work on <font color="red">Continual Learning on Dynamic Graphs via Parameter Isolation</font> at SIGIR 2023 (Oral Presentation).</strong></li>
                    <li>News (Mar. 2023): <strong>We got <a href="https://www.wsdm-conference.org/2023/program/awards"> "Best Paper Honorable Mention"</a> at WSDM 2023 on our work <font color="red">Efficiently leveraging multi-level user intent for session-based recommendation via atten-mixer network.</font></strong></li>	     
		    <li>News (Oct. 2022): <strong>We presented our work on <font color="red">Efficiently leveraging multi-level user intent for session-based recommendation via atten-mixer network.</font> at WSDM 2023 (Oral Presentation).</strong></li>
                    <li>News (Aug. 2022): <strong>We presented our work on <font color="red">Evolutionary Preference Learning via Graph Nested GRU ODE for Session-based Recommendation"</font> at CIKM 2022 (Oral Presentation).</strong></li>

                  </ul>
                  <p></p>
                </td>
              </tr>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Interest</heading>
              <p>
		My research lies at the intersection of trustworthy machine learning, LLM-based agents, multimodal understanding, and AI safety. I design LLM-based agents that can reason, plan, and collaborate‚Äîboth with humans and with other agents‚Äîto solve data-centric problems in domains such as e-commerce and large-scale information services. A central thrust of my work is fusing language, vision and graph signals so models can perform rich cross-modal reasoning for downstreamtasks. <br>
               </p> 
		Methodologically, I draw on data mining and semi-/unsupervised learning while prioritizing robustness: detecting spurious correlations, quantifying uncertainty, and aligning agent behavior with human intent. My overarching goal is to advance AI systems that are powerful, safe, and reliable in real-world, high-stakes settings.
             <p>
		<i style="color: #eb002a"> ÊàëÊ≠£Âú®ÂØªÊâæ2025Âπ¥ÁßãÂ≠£ÂÖ•ËÅåÁöÑÂÖ®ËÅåÂ≤ó‰Ωç, Ê¨¢ËøéÈÇÆ‰ª∂ËÅîÁ≥ª! </i>
	      </p>
		<p>
		<i style="color: #eb002a"> I will graduate at 2025 Summer. Drop me an Email if your are recruting! </i>
	      </p>
            </td>
          </tr>
        </tbody></table>
	      
	<a id="Selected Publications"></a>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Selected Publications</heading>
			(* joint first authors)
              </td>
            </tr>
          </tbody>
        </table>
        <table style="padding:10px;width:100%;vertical-align:middle">
          <tbody>
		   <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>REVOLVE: Optimizing AI Systems by Tracking Response Evolution in Textual Optimization</papertitle></strong>
                <br>
		      <strong>Peiyan Zhang</strong>, Haibo Jin, Leyang Hu, Xinnuo Li, Liying Kang, Man Luo, Yangqiu Song, Haohan Wang 
                <br>
              <em>International Conference on Machine Learning (ICML)</em>, 2025
              <br>
		<a href="https://llm-revolve.netlify.app/">Website</a> /
                <a href="https://arxiv.org/abs/2412.03092">Paper</a> /
		<a href="https://github.com/Peiyance/REVOLVE">Code</a>
              </td>
            </tr>

		  <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>Reasoning Can Hurt the Inductive Abilities of Large Language Models</papertitle></strong>
                <br>
		     Haibo Jin, <strong>Peiyan Zhang</strong>,  Man Luo, Haohan Wang 
                <br>
              <em>Manuscript</em>, 2025
              <br>
		<a href="https://arxiv.org/abs/2505.24225">Paper</a>
              </td>
            </tr>

		  <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>From Hallucinations to Jailbreaks: Rethinking the Vulnerability of Large Foundation Models</papertitle></strong>
                <br>
		      Haibo Jin, <strong>Peiyan Zhang</strong>, Peiran Wang, Man Luo, Haohan Wang 
                <br>
              <em>Manuscript</em>, 2025
              <br>
		<a href="https://arxiv.org/abs/2505.24232">Paper</a>
              </td>
            </tr>

		  <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of LLMs</papertitle></strong>
                <br>
		     Haibo Jin, Ruoxi Chen, <strong>Peiyan Zhang</strong>, Andy Zhou, Yang Zhang, Haohan Wang 
                <br>
              <em>Manuscript</em>, 2025
              <br>
		<a href="https://arxiv.org/abs/2402.03299">Paper</a>
              </td>
            </tr>
		  
		  
		  <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems</papertitle></strong>
        <br>
		      Bang Liu, Xinfeng Li, Jiayi Zhang, Jinlin Wang, Tanjin He, Sirui Hong, Hongzhang Liu, Shaokun Zhang, Kaitao Song, Kunlun Zhu, Yuheng Cheng, Suyuchen Wang, Xiaoqiang Wang, Yuyu Luo, Haibo Jin, <strong>Peiyan Zhang</strong>, Ollie Liu, Jiaqi Chen, Huan Zhang, Zhaoyang Yu, Haochen Shi, Boyan Li, Dekun Wu, Fengwei Teng, Xiaojun Jia, Jiawei Xu, Jinyu Xiang, Yizhang Lin, Tianming Liu, Tongliang Liu, Yu Su, Huan Sun, Glen Berseth, Jianyun Nie, Ian Foster, Logan Ward, Qingyun Wu, Yu Gu, Mingchen Zhuge, Xiangru Tang, Haohan Wang, Jiaxuan You, Chi Wang, Jian Pei, Qiang Yang, Xiaoliang Qi, Chenglin Wu
               <br>       
	<em>Manuscript</em>, 2024
              <br>
                <a href="https://arxiv.org/abs/2504.01990">Paper</a> /
		 <a href="https://huggingface.co/papers/2504.01990">Huggingface</a>
              </td>
            </tr>
		  <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>Improving Sequential Recommendations via Bidirectional Temporal Data Augmentation with Pre-training</papertitle></strong>
                <br>
		      Juyong Jiang*, <strong>Peiyan Zhang*</strong>, Yingtao Luo, Chaozhuo Li, Jaeboum Kim, Kai Zhang, Senzhang Wang, Sunghun Kim 
                <br>
              <em>IEEE Transactions on Knowledge and Data Engineering (TKDE)</em>, 2025
              <br>
                <a href="https://arxiv.org/pdf/2112.06460">Paper</a> /
		<a href="https://github.com/juyongjiang/BARec">Code</a>
              </td>
            </tr>
		  
		  
		<tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>Towards Graph Prompt Learning: A Survey and Beyond</papertitle></strong>
                <br>
		      Qingqing Long, Yuchen Yan, <strong>Peiyan Zhang*</strong>, Chen Fang, Wentao Cui, Zhiyuan Ning, Meng Xiao, Ning Cao, Xiao Luo, Lingjun Xu, Shiyue Jiang, Zheng Fang, Chong Chen, Xian-Sheng Hua and Yuanchun Zhou 
                <br>
              <em>Manuscript</em>, 2024
              <br>
                <a href="https://arxiv.org/html/2408.14520v2">Paper</a> 
              </td>
            </tr>
		  
		  <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>JailbreakZoo: Survey, Landscapes, and Horizons in Jailbreaking Large Language and Vision-Language Models</papertitle></strong>
                <br>
		      Haibo Jin, Leyang Hu, Xinuo Li, <strong>Peiyan Zhang*</strong>, Chonghan Chen, Jun Zhuang, Haohan Wang 
                <br>
              <em>Manuscript</em>, 2024
              <br>
		<a href="https://chonghan-chen.com/llm-jailbreak-zoo-survey/">Website</a> /
                <a href="https://arxiv.org/pdf/2407.01599">Paper</a> 
              </td>
            </tr>
		  
		  <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>GPT4Rec: Graph Prompt Tuning for Streaming Recommendation</papertitle></strong>
                <br>
		      <strong>Peiyan Zhang*</strong>, Yuchen Yan*, Chaozhuo Li, Liying Kang, Xi Zhang, Feiran Huang, Senzhang Wang and Sunghun Kim
                <br>
              <em>International ACM SIGIR Conference (SIGIR)</em>, 2024
		      <br>
              <font color="red"><strong>Oral Presentation</strong></font>
              <br>
		<a href="https://arxiv.org/pdf/2406.08229">Paper</a>
              </td>
            </tr>


		  <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>TransGNN: Harnessing the Collaborative Power of Transformers
and Graph Neural Networks for Recommender Systems</papertitle></strong>
                <br>
		      <strong>Peiyan Zhang*</strong>, Yuchen Yan*, Chaozhuo Li, Xi Zhang, Senzhang Wang, Xing Xie, Sunghun Kim
                <br>
              <em>International ACM SIGIR Conference (SIGIR)</em>, 2024
		      <br>
              <font color="red"><strong>Oral Presentation</strong></font>
              <br>
                <a href="https://arxiv.org/pdf/2308.14355.pdf">Paper</a> /
		<a href="https://github.com/Peiyance/TransGNN-torch">Code</a>
              </td>
            </tr>

		  
	<tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>High-Frequency-aware Hierarchical Contrastive Selective Coding for Representation Learning on Text Attributed Graphs</papertitle></strong>
                <br>
		      <strong>Peiyan Zhang</strong>, Chaozhuo Li, Liying Kang, Feiran Huang, Senzhang Wang, Xing Xie, Sunghun Kim
                <br>
              <em>International World Wide Web Conference (WWW)</em>, 2024
              <br>
              <font color="red"><strong>Poster Presentation</strong></font>
              <br>
		<a href="https://arxiv.org/pdf/2402.16240.pdf">Paper</a>
              </td>
            </tr>
	<tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>Inductive Graph Alignment Prompt: Bridging the Gap between Graph Pre-training and Inductive Fine-tuning From Spectral Perspective</papertitle></strong>
                <br>
		      Yuchen Yan, <strong>Peiyan Zhang</strong>, Zheng Fang, QingqingLong
                <br>
              <em>International World Wide Web Conference (WWW)</em>, 2024
              <br>
              <font color="red"><strong>Oral Presentation</strong></font>
              <br>
		<a href="https://arxiv.org/pdf/2402.13556v1.pdf">Paper</a>
              </td>
            </tr>

	<tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models</papertitle></strong>
                <br>
		      <strong>Peiyan Zhang</strong>, Haoyang Liu, Chaozhuo Li, Xing Xie, Sunghun Kim, Haohan Wang
                <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2024
              <br>
              <font color="red"><strong>Poster Presentation</strong></font>
              <br>
		<a href="https://arxiv.org/pdf/2308.10632.pdf">Paper</a>
              </td>
            </tr>

	<tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>A Comprehensive Study on Text-attributed Graphs: Benchmarking and Rethinking</papertitle></strong>
                <br>
		Hao Yan, Chaozhuo Li, Ruosong Long, Chao Yan, Jianan Zhao, Wenwen Zhuang, Jun Yin, <strong>Peiyan Zhang</strong>, Weihao Han, Hao Sun, Weiwei Deng, Qi Zhang, Lichao Sun, Xing Xie, Senzhang Wang

                <br>
              <em>Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS)</em>, 2023
              <br>
              <font color="red"><strong>Poster Presentation</strong></font>
              <br>
		<a href="https://openreview.net/pdf?id=m2mbfoSuJ1">Paper</a> /
                <a href="https://github.com/sktsherlock/TAG-Benchmark">Code</a>
              </td>
            </tr>
		  
		  
	<tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>AdaMCT: Adaptive Mixture of CNN-Transformer for Sequential Recommendation</papertitle></strong>
                <br>
		Juyong Jiang*, <strong>Peiyan Zhang*</strong>, Yingtao Luo, Chaozhuo Li, Jaeboum Kim, Kai Zhang, Senzhang Wang, Xing Xie and Sunghun Kim
                <br>
              <em>International ACM CIKM Conference (CIKM)</em>, 2023
              <br>
              <font color="red"><strong>Oral Presentation</strong></font>
              <br>
		<a href="https://arxiv.org/pdf/2205.08776.pdf">Paper</a> /
                <a href="https://github.com/juyongjiang/AdaMCT">Code</a>
              </td>
            </tr>

	<tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>Practical Content-aware Session-based Recommendation: Deep Retrieve then Shallow Rank</papertitle></strong>
                <br>
		Yuxuan Lei, Xiaolong Chen, Defu Lian, <strong>Peiyan Zhang</strong>, Jianxun Lian, Chaozhuo Li, Xing Xie
                <br>
              <em>International ACM KDD Conference (KDD) workshop</em>, 2023
              <br>
              <font color="red"><strong>Oral Presentation</strong></font>
              <br>
		<a href="https://openreview.net/pdf?id=6MdSsLgDei">Paper</a>
              </td>
            </tr>
		  
            <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>Continual Learning on Dynamic Graphs via Parameter Isolation</papertitle></strong>
                <br>
                <strong>Peiyan Zhang*</strong>, Yuchen Yan*, Chaozhuo Li, Senzhang Wang, Xing Xie, Guojie Song, Sunghun Kim
                <br>
                <em>International ACM SIGIR Conference (SIGIR)</em>, 2023
                <br>
		<font color="red"><strong>Oral Presentation</strong></font>
		<br>
                <a href="https://arxiv.org/pdf/2305.13825.pdf">Paper</a> /
                <a href="https://github.com/jerry2398/pi-gnn">Code</a>
              </td>
            </tr>
		  
	    <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>Efficiently Leveraging Multi-level User Intent for Session-based Recommendation via Atten-Mixer Network</papertitle></strong>
                <br>
                <strong>Peiyan Zhang*</strong>, Jiayan Guo*, Chaozhuo Li, Yueqi Xie, Jaeboum Kim, Yan Zhang, Xing Xie, Haohan Wang, Sunghun Kim
                <br>
              <em>International ACM WSDM Conference (WSDM)</em>, 2023
              <br>
              <font color="red"><strong>Oral Presentation, Best Paper Award Honorable Mention</strong></font>
              <br>
                <a href="https://arxiv.org/pdf/2206.12781.pdf">Paper</a> /
                <a href="https://github.com/Peiyance/Atten-Mixer-torch">Code</a>
              </td>
            </tr>
		  <tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>A Survey on Incremental Update for Neural Recommender Systems</papertitle></strong>
                <br>
		      <strong>Peiyan Zhang</strong>, Sunghun Kim
                <br>
              <em>Manuscript</em>, 2023
              <br>
                <a href="https://arxiv.org/pdf/2303.02851.pdf">Paper</a> 
              </td>
            </tr>

		<tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>Evolutionary Preference Learning via Graph Nested GRU ODE for Session-based Recommendation</papertitle></strong>
                <br>
		      Jiayan Guo*, <strong>Peiyan Zhang*</strong>, Chaozhuo Li, Xing Xie, Yan Zhang, Sunghun Kim

                <br>
              <em>ACM International ACM CIKM Conference (CIKM)</em>, 2022
		<br>
		<font color="red"><strong>Oral Presentation</strong></font>
		<br>
                <a href="https://arxiv.org/pdf/2206.12779.pdf">Paper</a> /
                <a href="https://github.com/SpaceLearner/GNG-ODE">Code</a>
              </td>
            </tr>

	<tr onmouseout="dif_stop()" onmouseover="dif_start()">
              <td style="padding:5px 25px;width:100%;vertical-align:middle">
                <strong><papertitle>Word shape matters: Robust machine translation with visual embedding</papertitle></strong>
                <br>
		      Haohan Wang, <strong>Peiyan Zhang</strong>, Eric P Xing
                <br>
              <em>Manuscript</em>, 2020
              <br>
                <a href="https://arxiv.org/pdf/2010.09997.pdf">Paper</a> 
              </td>
            </tr>

      


	  </tbody>
	
       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Services</heading>
                  <ul>
		   <li>PC-Member</li>
		<ul>	
			<li>SIGIR-AP 2025</li>
			<li>SIGIR 2025</li>
			<li>AAAI 2025</li>
		   <li>WWW 2024 Data-centric Artificial Intelligence Workshop</li>
		<li>KDD 2024 Ethical Artificial Intelligence Workshop</li>
		</ul>
		    <li>Reviewer</li>
		<ul>
		    <li>Conference: NeurIPS, ICLR, ICML, KDD, WWW, CVPR, EMNLP, AAAI, IJCAI, PAKDD, AISTAT</li>
		     <li>Journal: IEEE Transactions on Neural Networks and Learning Systems, Neurocomputing, Neural Networks, Information Fusion, Neural Computing & Applications, Future Generation Computer Systems, Computers in Biology and Medicine</li>
                </ul>  
		</ul>              
              </td>
            </tr>
          </tbody></table>
		


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Selected Honors and Awards</heading>
                  <ul>
		    <li>Excellence in Review Award by Future Generation Computer Systems (FGCS)</li>
		    <li>ACM SIGIR Student Travel Grant for SIGIR 2024</li>
		    <li>Award of Excellence of Stars of Tomorrow Internship Program <b>(Top 10%)</b>, 2023 (Microsoft Research Asia)</li>
		    <li>Winners of Amazon KDD Cup 2023 Challenge <b>(3rd Place)</b>, 2023 (KDDCup 2023)</li>
		     <li><b>Best Paper Award - Honorable Mention</b>, 2023 (WSDM 2023)</li>
		     <li>RedBird PhD Scholarship, 2020 (Hong Kong University of Science and Technology)</li>
		     <li>Graduate Excellence Award of Beijing <b>(top 1%)</b>, 2020 (Ministry of Education, PRC)</li>
                    <li>National Scholarship <b>(top 0.2%)</b>, 2019 (Ministry of Education, PRC)</li>
		    <li>National Scholarship <b>(top 0.2%)</b>, 2018 (Ministry of Education, PRC)</li>
		    <li>National Scholarship <b>(top 0.2%)</b>, 2017 (Ministry of Education, PRC)</li>
                  </ul>              
              </td>
            </tr>
          </tbody></table>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">Thanks <a href="https://jonbarron.info/">Dr. Jon Barron</a> for sharing the source code of his personal page.</p>
                  <!-- <br> -->
                </p>
              </td>
            </tr>
          </tbody></table>

	<table width="35%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
                <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=QgKnCQiEO0QSKX3DC1xH48RmACyNaiz8OLb_zCoCRSo&cl=ffffff&w=a"></script>
              </td>
          </tr>
        </tbody></table>

      </td>
      
    </tr>
  </table>
</body>

</html>
